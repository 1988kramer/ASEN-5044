\documentclass[11pt]{article}

% ==== PACKAGES ==== %
% \usepackage{fullpage}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{epic}
\usepackage{eepic}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{float}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{bbm}
\usepackage[letterpaper, margin=1in]{geometry}

% ==== MARGINS ==== %
% \pagestyle{empty}
% \setlength{\oddsidemargin}{0in}
% \setlength{\textwidth}{6.8in}
% \setlength{\textheight}{9.5in}

\pagestyle{fancy}
\fancyhf{}
\rhead{ASEN 5044}
\lhead{Midterm 2}
\rfoot{Page \thepage}


\newtheorem*{solution*}{Solution}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{claim}[lemma]{Claim}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{corollary}[lemma]{Corollary}
\lstset{moredelim=[is][\bfseries]{[*}{*]}}

% ==== DOCUMENT PROPER ==== %
\begin{document}

\thispagestyle{empty}

% --- Header Box --- %
\newlength{\boxlength}\setlength{\boxlength}{\textwidth}
\addtolength{\boxlength}{-4mm}

\begin{center}\framebox{\parbox{\boxlength}{\bf
      Statistical Estimation \hfill Midterm 2\\
      ASEN 5044 Fall 2018 \hfill Due Date: Nov 15, 2018\\
      Name: Andrew Kramer \hfill PhD Student
}}
\end{center}

\section*{Problem 1}
Suppose that a dynamic scalar system is given as $x_{k+1}=f_{x_k}+w_k$ where $w_k$ is zero-mean white noise with variance $q$. Show that if the variance of $x_k$ is $\sigma^2$ for all $k$, then it must be true that $f^2=(\sigma^2-q)/\sigma^2$. \textbf{Hint:} The problem says the variance of $x_k$ is $\sigma^2$ for all time steps $k$. It does \textit{not} say $x_k$ is zero mean for all $k$.

\subparagraph*{}
If we start with the assumption that $x_k\sim\mathcal{N}(\mu_k,\sigma^2)$ and $w_k\sim\mathcal{N}(0,q)$, then we can find the variance of $x_{k+1}$ as the variance of the linear combination $fx_k+w_k$:
\begin{equation*}
	\sigma_{x_{k+1}}^2 = f^2\sigma_{x_k}^2 + q
\end{equation*}
But since $x_k$ has the same variance at all timesteps $k$ the expression becomes $\sigma^2=f^2\sigma^2+q$. If we solve this equation for $f^2$ we get
\begin{equation*}
	f^2 = \frac{\sigma^2-q}{\sigma^2}
\end{equation*}

\section*{Problem 2}
Given the random vector $x\in\mathbb{R}^n$ (with some finite mean and covariance matrix) and the constant non-random matrix $A\in\mathbb{R}^{n\times n}$ where $A=A^T$, find $\mathbb{E}[x^TAx]$. Be sure to show and properly explain all steps used to get your result. \textbf{Hint:} Ref lecture 2, slide 2. Think about the size of the result of the quadratic form to see the relevant connection. To use this fact, you should first prove that, if $Z$ is a square matrix whose elements are random variables then $\mathbb{E}[\text{tr}(AZ)]=\text{tr}(A\mathbb{E}[Z])$.

\subparagraph*{}
$\mathbb{E}[x^TAx]$ can be broken down as follows:
\begin{align*}
	\mathbb{E}[x^TAx] &= \mathbb{E}\Bigg[\sum_{i=1}^n\sum_{j=1}^n a_{ij}x_ix_j\Bigg] \\
	&= \sum_{i=1}^n\sum_{j=1}^na_{ij}\mathbb{E}[x_ix_j]\\
	&= \sum_{i=1}^n\sum_{j=1}^na_{ij}\Bigg[\text{cov}(x_ix_j)+\mathbb{E}[x_i]\mathbb{E}[x_j]\Bigg] \\
	&= \sum_{i=1}^n\sum_{j=1}^n a_{ij}(\sigma_{ji}+\mu_i\mu_j)\quad \text{noting: } \text{cov}(x_ix_j)=\text{cov}(x_jx_i)\\
	&= \sum_{i=1}^n\sum_{j=1}^n a_{ij}\sigma_{ji} + \sum_{i=1}^n\sum_{j=1}^n a_{ij}\mu_i\mu_j \\
	&= \text{tr}(AP) + \mu^TA\mu
\end{align*}
where $\sigma_{ij}$ is the covariance between $x_i$ and $x_j$, $P$ is the full covariance matrix of $x$, and $\mu$ is the expected value of $x$.

\section*{Problem 3}
Consider the coordinated turning aircraft problem from homework 7. Assume again the dynamics are free of process noise,
\begin{equation*}
	x(k+1)=Fx(k)
\end{equation*}
for the $F$ matrix and states as defined in homework 7 for some unknown turning rate $\Omega$ and discretization step $\Delta T$. Now add measurements of the form 
\begin{align*}
	y(k+1)&=Hx(k+1)+v(k) \\
	\mathbb{E}[v(k)] &= 0,\quad \mathbb{E}[v(k)v(j)^T] = \delta(k,j)R(k)
\end{align*}
with additive white noise $v(k)$ and non-stationary noise covariance $R(k)$. For each part of this problem, it is desired to estimate the initial state $x(0)\in\mathbb{R}^n$ of a dynamical system consisting of either one or two turning aircraft at time $k=0$ from noisy measurements $y(k)\in\mathbb{R}^p$ taken at time steps $k=1,2,\dots,T$.

\subsection*{part (a)}
Derive an analytical expression for the batch estimator $\hat{x}(0)$ which minimizes the cost function
\begin{equation*}
	J(T)=\sum_{k=1}^T(y_k-\hat{y}_k)^T[R(k)]^{-1}(y_k-\hat{y}_k)
\end{equation*}
where $\hat{y}_k$ is the time $k$ estimator-based predicted measurement (a function of $\hat{x}(0)$) and $y_k$ is the actual measurement at time $k$. Be sure to precisely and carefully define all matrices and vectors used by the estimator, for the case where $x_k$ and $y_k$ obey equations (1) and (2).

\subparagraph*{}
The cost function is
\begin{align*}
	J(T) &= \sum_{k=1}^T(y_k-\hat{y}_k)^T[R(k)]^{-1}(y_k-\hat{y}_k) \\
	&= \sum_{k=1}^T(y_k-Hx(k))^T[R(k)]^{-1}(y_k-Hx(k)) \\
	&= \sum_{k=1}^T(y_k-HF^kx(0))^T[R(k)]^{-1}(y_k-HF^kx(0)) \\
	&= \sum_{k=1}^T \Big(y_k^T[R(k)]^{-1}y_k - y_k^T[R(k)]^{-1}HF^kx(0) \\
	&\qquad-x(0)^T[F^k]^TH^T[R(k)]^{-1}y_k + x(0)^T[F^k]^TH^T[R(k)]^{-1}HF^kx(0) \Big) \\
	&= \sum_{k=1}^T (y_k^TR(k)^{-1}y_k - M_1(k)x(0) - x(0)^TM_2(k)+x(0)^TM_3(k)x(0))
\end{align*}
Where $M_1(k) = y_k^TR(k)^{-1}y_kHF^k$, $M_2(k) = (F^k)^TH^TR(k)^{-1}y_k$, and $M_3(k)=(F^k)^TH^TR(k)^{-1}HF^k$. We should note that because $R(k)$ is symmetric its inverse is also symmetric. This means $M_1(k)^T=M_2(k)$. The batch LLS estimate for $\hat{x}(0)$ is
\begin{equation*}
	\hat{x}(0) = \text{argmin}_{x(0)}J(T)
\end{equation*}
so we need to find the $x(0)$ that produces the minimum value for the cost function $J(T)$. We do this by finding the value of $x(0)$ at which the derivative of the cost function with respect to $x(0)$, $\nabla_{x(0)}J(T)$ is equal to zero. Noting, as we did in lecture 21, slide 6 that 
\begin{align*}
	\frac{\partial}{\partial x}(x^TMx) &= 2Mx \qquad \text{when $M$ is symmetric}\\ 
	\frac{\partial}{\partial x}M^Tx &= \frac{\partial}{\partial x}x^TM = M \qquad \text{for any M}
\end{align*}
This means the derivative of our cost function is
\begin{align*}
	\nabla_{x(0)}J(T) &= \sum_{k=1}^T (2M_3(k)x(0)-2M_2(k)) \\
	&= \sum_{k=1}^T (2[F^k]^TH^T[R(k)]^{-1}HF^kx(0)-2[F^k]^TH^TR(k)^{-1}y_k)
\end{align*}
We can get rid of the summations by stacking the $y_k$ vectors into a $\mathbb{Y}$ vector, rearranging the $R(k)^{-1}$ matrices into a block diagonal $\mathbb{R}^{-1}$ matrix, and stacking the $HF^k$ matrices (with dimension $p\times n$) into a $\mathbb{H}$ matrix (with dimension $pT\times n$). This results in 
\begin{equation*}
	\nabla_{x(0)}J(t) = 2\mathbb{H}^T\mathbb{R}^{-1}\mathbb{H}x(0) - 2\mathbb{H}^T\mathbb{R}^{-1}\mathbb{Y}
\end{equation*}
To find the LLS estimate $\hat{x}(0)$, the above equation for $\nabla_{x(0)}J(T)$ is set equal to zero and solved for $x(0)$:
\begin{align*}
	0 &= 2\mathbb{H}^T\mathbb{R}^{-1}\mathbb{H}\hat{x}(0)-2\mathbb{H}^T\mathbb{R}^{-1}\mathbb{Y} \\
	2\mathbb{H}^T\mathbb{R}^{-1}\mathbb{Y} &= 2\mathbb{H}^T\mathbb{R}^{-1}\mathbb{H}\hat{x}(0) \\
	\hat{x}(0) &= (2\mathbb{H}^T\mathbb{R}^{-1}\mathbb{H})^{-1}2\mathbb{H}^T\mathbb{R}^{-1}\mathbb{Y}
\end{align*}

\subsection*{part (b)}
Suppose a ground tracking station monitors aircraft $A$ which is turning with $\Omega_A=0.045$ rad/s and converts 3D range and bearing data into 2D pseudo-measurements $y_A(k)$ with the following DT measurement model
\begin{align*}
	y_A(k) &= Hx_A(k)+v_A(k) \\
	H = \begin{bmatrix} 1&0&0&0\\0&0&1&0 \end{bmatrix},\quad R_A &= \begin{bmatrix} 75&7.5\\7.5&75 \end{bmatrix} + \begin{bmatrix} 12.5\sin(k/10) & 25.5\sin(k/10) \\ 25.5\sin(k/10) & 12.5\cos(k/10) \end{bmatrix}
\end{align*}
where $R_A$ has units of $\text{m}^2$. Using the data posted in \texttt{midterm2\_problem3b.mat}, use your result from part (a) to compute the estimate $x_A(0)$, and report the final state estimation error covariance matrix. Note the data provided is for time steps $k\geq1$ and each column $k$ corresponds to a single $y_k$ vector at step $k$.

\subsection*{}
The estimate for the initial state is $\hat{x}_A(0) = [7121,\ -13647,\ -180,\ 774]^T$. The final state estimation error covariance is 
\begin{equation*}
	\text{cov}(e_\text{LS})=(\mathbb{H}^T\mathbb{R}^{-1}\mathbb{H})^{-1} = \begin{bmatrix} 0.906&-1.81&0.116&-0.212 \\ -1.81&310&-0.252&41.4 \\ 0.116&-0.252&0.896&-1.79 \\ -0.2124&41.1&-1.79&352 \end{bmatrix}
\end{equation*}

\subsection*{part (c)}
Suppose now there is a second aircraft $B$ which is turning with $\Omega_B=-0.045$ rad/s. The tracking station can only directly sense one aircraft at a time, and thus cannot sense $B$ while it senses $A$. However, a transponder between $A$ and $B$ provides a noisy measurement $y_D(k)$ of the difference in their 2D positions as they are turning, $r_A=[\xi_A,\eta_A]^T$ and $r_B=[\xi_B,\eta_B]$,
\begin{align*}
	y_D(k)&=r_A(k)-r_B(k)+v_D(k) \\
	R_D &= \begin{bmatrix} 8000 & 500 \\ 500 & 8000 \end{bmatrix}
\end{align*}
where $R_D$ has units of $\text{m}^2$ and $v_D\sim\mathcal{N}(0,R_D)$ follows a stationary white noise process. Using the data posted in \texttt{midterm2\_problem3c.mat} in the array 'yaugHist' (where each column contains a concatenated $4\times1$ vector $[y_A^T(k),y_D^T(k)]^T$ that includes a new set of $y_A(k)$ measurements for time steps $k\geq1$), compute an RLLS estimate for $x(0)=[x_A(0),x_B(0)]^T$. In separate plots, show the evolution of each aircraft's state estimate vs $k$ using 4 subplots per aircraft. Also on 4 separate subplots per aircraft show positive $2\sigma$ bounds ofr each estimated state vs $k$. Be sure to explain how you set up the RLLS estimator to estimate $x(0)$ and how you initialized the estimator.

\subparagraph*{}
We can first combine the measurements into a single measurement vector $y(k)=[y_A(k),\ y_D(k)]^T$. We can say in this case that $y(k) = H_Dx(k)$ where $x(k) = [x_A(k),\ x_B(k)]^T$ and
\begin{equation*}
	H_D = \begin{bmatrix} H & 0 \\ H & -H \end{bmatrix} = \begin{bmatrix} 1&0&0&0&0&0&0&0 \\ 0&0&1&0&0&0&0&0 \\ 1&0&0&0&-1&0&0&0 \\ 0&0&1&0&0&0&-1&0 \end{bmatrix}
\end{equation*}
We can put this in terms of $x(0)$ if $H_D(k)$ is 
\begin{equation*}
	H_D(k) = \begin{bmatrix} HF_A^k & 0 \\ HF_A^k & -HF_B^k \end{bmatrix}
\end{equation*}
So the full measurement function is $y(k)=H_D(k)x(0)+v(k)$ where $v(k)\sim\mathcal{N}(0,R(k))$
\begin{equation*}
	R(k) = \begin{bmatrix} R_A(k) & 0 \\ 0 & R_D \end{bmatrix}
\end{equation*}
So we can set up our RLLS estimator for $x(0)$ as 
\begin{align*}
	K_k &= P_{k-1}H_D(k)^T(H_D(k)P_{k-1}H_D(k)^T + R(k))^{-1} \\
	\hat{x}_k(0) &= \hat{x}_{k-1}(0) + K_k(y_k-H_D(k)\hat{x}_{k-1}(0)) \\
	P_k &= (I-K_kH_D(k))P_{k-1}(I-K_kH_D(k))^T + K_kR(k)K_k^T
\end{align*}
and we initialize our estimator using a batch estimate from the first 2 measurements, because the system is observable with 2 measurements.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{prob3c_plt1.png}
	\caption{Estimate of initial conditions for aircraft 1}
	\label{xA0}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{prob3c_plt2.png}
	\caption{Estimate of initial conditions for aircraft 2}
	\label{xB0}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{prob3c_plt3.png}
	\caption{Variance of initial condition estimate for aircraft 1}
	\label{sigmaA}
\end{figure}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\textwidth]{prob3c_plt4.png}
	\caption{Variance of initial condition estimate for aircraft 2}
	\label{sigmaB}
\end{figure}

\end{document}

