\documentclass[11pt]{article}

% ==== PACKAGES ==== %
% \usepackage{fullpage}
\usepackage{amsmath,amssymb,amsthm}
\usepackage{epic}
\usepackage{eepic}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{float}
\usepackage{graphicx}
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{bbm}
\usepackage[letterpaper, margin=1in]{geometry}

% ==== MARGINS ==== %
% \pagestyle{empty}
% \setlength{\oddsidemargin}{0in}
% \setlength{\textwidth}{6.8in}
% \setlength{\textheight}{9.5in}

\pagestyle{fancy}
\fancyhf{}
\rhead{ASEN 5044}
\lhead{Homework 1}
\rfoot{Page \thepage}


\newtheorem*{solution*}{Solution}
\newtheorem{lemma}{Lemma}[section]
\newtheorem{theorem}[lemma]{Theorem}
\newtheorem{claim}[lemma]{Claim}
\newtheorem{definition}[lemma]{Definition}
\newtheorem{corollary}[lemma]{Corollary}
\lstset{moredelim=[is][\bfseries]{[*}{*]}}

% ==== DOCUMENT PROPER ==== %
\begin{document}

\thispagestyle{empty}

% --- Header Box --- %
\newlength{\boxlength}\setlength{\boxlength}{\textwidth}
\addtolength{\boxlength}{-4mm}

\begin{center}\framebox{\parbox{\boxlength}{\bf
      Statistical Estimation \hfill Homework 2\\
      ASEN 5044 Fall 2018 \hfill Due Date: Sep 20, 2018\\
      Name: Andrew Kramer \hfill PhD Student
}}
\end{center}

\section*{Exercise 1}
In the game of blackjack, the player is initially dealt two cards from a deck of ordinary playing cards. Without going into all the game's details, it is enough to know the best possible hand for a player to receive on the initial deal is a combination of an ace of any suit and any face card or ten. What is the probability that a player will be dealt this combination?

\subparagraph*{}
The number of ways a single player can be dealt a blackjack (assuming there is only one player) is ${4\choose1}{16\choose1} = 64$. So the number of events in our event space (which we'll call $A$) is 64. The total number of ways to deal 2 cards to that player is ${52\choose2} = 1326$. So, the number of events in the whole sample space is 1326. the probability of a single player being dealt a blackjack is therefore
\begin{equation*}
	\frac{N_A}{N} = \frac{{4\choose1}}{{16\choose1}} = \frac{64}{1326} = 0.048
\end{equation*}

\section*{Exercise 2}
Discrete and random variables $X$ and $Y$ can each take on integer values 1, 3, and 5. The joint probability table of $X$ and $Y$ is given below.

\begin{table}[h!]
  \begin{center}
    \caption{Joint Probabilities}
    \label{tab:table1}
    \begin{tabular}{c|c|c|c} % <-- Alignments: 1st column left, 2nd middle and 3rd right, with vertical lines in between
      X & Y=1 & Y=3 & Y=5\\
      \hline
      1 & 1/18 & 1/18 & 1/18 \\
      3 & 1/18 & 1/18 & 1/6 \\
      5 & 1/18 & 1/6 & 1/3\\
    \end{tabular}
  \end{center}
\end{table}

\subsection*{Problem (a)}
Are the random variables $X$ and $Y$ independent?

\subparagraph*{}
No, the table clearly shows that the probability of $X$ taking on certain values changes depending on the value of $Y$. For instance $P(X=3|Y=3)\neq P(X=3|Y=5)$ If $X$ and $Y$ were independent then $P(X=x|Y=y)$ would be the same for all values of $y$.

\subsection*{Problem (b)}
Find the unconditional (marginal) probability $P(Y=5)$.

\subparagraph*{}
The marginal probability $P(Y=5) = P(Y=5|X=1) + P(Y=5|X=3) + P(Y=5|X=5) = (1/18) + (1/6) + (1/3) = (5/9)$.

\subsection*{Problem (c)}
What is the conditional probability $P(Y=5|X=3)$?

\subparagraph*{}
Generally $P(A|B)=\frac{P(A,B)}{P(B)}$. This means we need to calculate the marginal probability $P(X=3)=(1/18)+(1/18)+(1/6)=(5/18)$. With this information we can find
\begin{equation*}
	P(Y=5|X=3)=\frac{P(Y=5,X=3)}{P(X=3)}=\frac{1/6}{5/18}=\frac{3}{5}
\end{equation*}

\section*{Exercise 3}
Determine the value of $a$ in the function 
\begin{equation*}
	f_X(x) = \begin{cases}
			 	ax(1-x) & x\in[0,1] \\
			 	0 & \text{otherwise}
			 \end{cases}
\end{equation*}
so that $f_X(x)$ is a valid probability density function.

\subparagraph*{}
For $f_X(x)$ to be a valid probability density function $\int_{-\infty}^{\infty}f_X(x)dx$ must be equal to one.
\begin{align*}
	1 &= \int_{-\infty}^{\infty}f_X(x)dx \\ 
	&= \int_{0}^{1}ax(1-x)dx \\
	&= a\int_{0}^{1}(x-x^2)dx \\
	&= a\Big[\frac{x^2}{2} - \frac{x^3}{3}\Big|_0^1 \\
	&= a\Big(\frac{1}{2}-\frac{1}{3}\Big) \\
	1 &= \frac{a}{6} \\
	a &= 6
\end{align*}

\section*{Exercise 4}
The probability density function of an exponentially distributed random variable is defined as follows
\begin{equation*}
	f_X(x)=\begin{cases}
		   		ae^{-ax} & x>0 \\
		   		0 & x\leq0 
		   \end{cases}
\end{equation*}
where $a\geq0$.

\subsection*{Problem (a)}
Find the probability distribution function of an exponentially distributed random variable.

\subparagraph*{}
\begin{align*}
	P(a\leq X\leq b) &= \int_a^b f_X(x)dx \\
	&= \int_a^b ae^{-ax}dx \\
	&= -e^{-ax}|_a^b
\end{align*}
assuming $0<a\leq b$.

\subsection*{Problem (b)}
Find the mean of an exponentially distributed random variable.

\subparagraph*{}
\begin{align*}
	E[X] &= \int_{-\infty}^\infty xf_X(x)dx \\
	&= a\int_0^\infty xe^{-ax}dx \\
	&= a\Bigg[\Big(-\frac{x}{a}-\frac{1}{a^2}\Big)e^{-ax}\Bigg|_0^\infty \\
	&= \Bigg[\Big(-x-\frac{1}{a}\Big)e^{-ax}\Bigg|_0^\infty \\
	&= \Big(-\infty-\frac{1}{a}\Big)e^{-a\infty} + \frac{1}{a}e^0
\end{align*}
Because $e^{-\infty}=0$, $E[X]=\frac{1}{a}$.

\subsection*{Problem (c)}
Find the second moment of an exponentially distributed random variable.

\subparagraph*{}
\subparagraph*{}
\begin{align*}
	E[X^2] &= \int_{-\infty}^\infty x^2f_X(x)dx \\
	&= \int_0^\infty x^2ae^{-ax}dx \\
	&= \frac{1}{a^2}\int_0^\infty t^2e^-tdt \\
	&= \frac{1}{a^2}\Gamma(2+1)=\frac{2!}{a^2} \\
	&= \frac{2}{a^2}
\end{align*}

\subsection*{Problem (d)}
Find the variance of an exponentially distributed random variable.

\subparagraph*{}
\begin{align*}
	\sigma_x^2 &= E[X^2]-(E[X])^2)\\
	&= \frac{2}{a^2} - \Big(\frac{1}{a}\Big)^2 \\
	&= \frac{1}{a^2}
\end{align*}

\subsection*{Problem (e)}
What is the probability that an exponentially distributed random variable takes on a value within one standard deviation of its mean?

\subparagraph*{}
The standard deviation is $\sqrt{\frac{1}{a}}=\frac{1}{a}$, so we simply need to evaluate the probability distribution function from $0$ to $\frac{2}{a}$:
\begin{align*}
	P\Big(0<X\leq\frac{2}{a}\Big) &= 1-e^{-ax}\Big|_0^{2/a} \\
	&= (1-e^{-a\frac{2}{a}})-(1-e^0) \\
	&= 1-e^{-2}
\end{align*}
So the probability that $X$ falls within one standard deviation of the mean is a constant, unrelated to the value of $a$.

\section*{Exercise 5}
Generate $N=50$ independent random numbers, each uniformly distributed between 0 and 1. Plot a histogram of the random numbers using 10 bins. What is the sample mean and standard deviation of the numbers that you generated? What would you expect to see for the mean and standard deviation? Repeat for $N=500$ and $N=5000$ random numbers. What changes do you see in the histogram as $N$ increases?

\subparagraph*{}
Our uniformly distributed probability density function is defined as
\begin{equation*}
	f(x) = \begin{cases}
				c & x \in [0,1] \\
				0 & \text{otherwise}
		   \end{cases}
\end{equation*}
Because $\int_{-\infty}^\infty f(x) = 1$, $c=1$. The expected value of this pdf is
\begin{align*}
	E[X] &= \int_{-\infty}^\infty xf(x)dx \\
	&= \int_0^1xdx \\
	&= \frac{1}{2}x^2\big|_0^1 \\
	&= \frac{1}{2}
\end{align*}
and the expected value of $X^2$ is
\begin{align*}
	E[X^2] &= \int_{-\infty}^\infty x^2f(x)dx \\
	&= \int_0^1 x^2dx \\
	&= \frac{1}{3}x^3\big|_0^1 \\
	&= \frac{1}{3}
\end{align*}
So the variance can be calculated as
\begin{equation*}
	\sigma^2 = E[X^2] - (E[X])^2 = \frac{1}{3} - \frac{1}{4} = \frac{1}{12}
\end{equation*}
which means the standard deviation is $\sqrt{\sigma^2} = 0.2887$. \\
With a sample size $N=50$ we get $\mu=0.4899$ and $\sigma=0.2786$, which is fairly close to the theoretical values. See figure \ref{5_plot1}, below, for a histogram of the experimental values. From the histogram we can see that the actual distribution of values is not terribly uniform.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{5_plot1.png}
	\caption{histogram for $N=50$}
	\label{5_plot1}
\end{figure}

With a sample size $N=500$ we get $\mu=0.4862$ and $\sigma=0.2898$, which is fairly close to the theoretical values, though the $\mu$ value is actually further from the theoretical value than when $N=50$. See figure \ref{5_plot2}, below, for a histogram of the experimental values. From the histogram we can see that the actual distribution of values is more uniform than in the previous case, though it still has distinct peaks that one would not expect with a truly uniform distribution.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{5_plot2.png}
	\caption{histogram for $N=500$}
	\label{5_plot2}
\end{figure}

With a sample size $N=500$ we get $\mu=0.4999$ and $\sigma=0.2892$, which is nearly the same as the theoretical values. See figure \ref{5_plot3}, below, for a histogram of the experimental values. From the histogram we can see that the actual distribution of values is very nearly uniform, with each of the 10 bins containing about 500 values.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{5_plot3.png}
	\caption{histogram for $N=5000$}
	\label{5_plot3}
\end{figure}

\section*{Exercise 6}
Generate $10000$ samples of $(x_1+x_2)/2$, where each $x_i$ is a random number uniformly distributed on $[-1/2,+1/2]$. Plot the samples in a 50-bin histogram. Repeat for $(x_1+x_2+x_3+x_4)/4$. Describe the difference between the two histograms.

\subparagraph*{}
The plot below shows a histogram for $10000$ samples of $(x_1 + x_2)/2$. Because each value in this distribution is the mean of two samples from a uniform probability distribution one would expect the distribution to be more heavily weighted toward the mean and to taper off linearly as $x$ diverges from the mean. This is exactly what we see in figure \ref{6_plot1}, below.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{6_plot1.png}
	\caption{histogram for $(x_1 + x_2)/2$}
	\label{6_plot1}
\end{figure}

The plot below shows a histogram for $10000$ samples of $(x_1 + x_2 + x_3 + x_4)/4$. Because each value in this distribution is the mean of four samples from a uniform probability distribution one would expect the distribution to be more heavily weighted toward the mean as in the previous case. However, instead of tapering linearly we would expect the tapering to approximate a polynomial shape. Again, this is what we see in figure \ref{6_plot2}, below.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{6_plot2.png}
	\caption{histogram for $(x_1 + x_2 + x_3 + x_4)/4$}
	\label{6_plot2}
\end{figure}

\section*{AQ 1}
Consider the following probability density function:
\begin{equation*}
	f_X(x) = \frac{ab}{b^2+x^2},\quad b>0
\end{equation*}

\subsection*{Problem (a)}
Determine the value of a in the pdf so that $f_X(x)$ is a valid probability density function. Note: the correct value of $a$ makes $f_X(x)$ a Cauchy pdf.

\subparagraph*{}
Knowing $\int_{-\infty}^\infty f_X(x)dx = 1$ we can find $a$ via the following:
\begin{align*}
	1 &= \int_{-\infty}^\infty \frac{ab}{b^2+x^2}dx \\
	&= ab\int_{-\infty}^\infty \frac{1}{b^2 + x^2}dx \\
	&= ab\Bigg[\frac{1}{b}\tan^{-1}\frac{x}{b}\Bigg|_{-\infty}^\infty \\
	&= a\tan^{-1}\frac{x}{b}\Bigg|_{-\infty}{\infty} \\
	&= \frac{a\pi}{2}  + \frac{a\pi}{2} \\
	&= a\pi \\ 
	a &= \frac{1}{\pi}
\end{align*}

\subsection*{Problem (b)}
Find the mean of a Cauchy random variable.

\subparagraph*{}
If we try to find the mean of the Cauchy random variable as $E[X]=\int_{-\infty}^\infty xf_X(x)dx$ we find:
\begin{align*}
	\int_{-\infty}^\infty xf_X(x)dx &= \frac{b}{\pi}\int_{-\infty}^\infty\frac{x}{b^2+x^2}dx \\
	&= \frac{b}{2\pi}\ln|b^2+x^2|\Big|_{-\infty}^\infty 
\end{align*}
The above indefinite integral can be evaluated by breaking it up into two separate integrals:
\begin{equation*}
	\frac{b}{2\pi}\ln|b^2+x^2|\Big|_{-\infty}^\infty = \frac{b}{2\pi}\ln|b^2+x^2|\Big|_{0}^\infty + \frac{b}{2\pi}\ln|b^2+x^2|\Big|_{-\infty}^0
\end{equation*}
However, both of the terms in this equation are infinite and have opposite signs so the mean of the Cauchy distribution is undefined.

\section*{AQ 2}

Consider a continuous random variable $x$ whose probability density function $p(x)$ is given by a mixture model consisting of $M$ weighted uniform pdfs,
\begin{equation*}
	p(x) = \sum_{i=1}^Mw_iU[a_i,b_i],
\end{equation*}
where $w_i\geq0$, $\sum_{i=1}^Mw_i=1$, and $a_i<b_i$ for all mixture components ('mixands') $i=1,\dots,M$.

\subsection*{Problem (a)}
Find general closed-form expressions for $E[x]$ and $\text{var}[x]$ in terms of the means $u_i$ and variances $\sigma_i^2$ of the individual mixands $U[a_i,b_i]$.

\subparagraph*{}
\begin{align*}
	E[x]&=\int_{-\infty}^\infty x\sum_{i=1}^Mw_iU[a_i,b_i]dx \\
	&= \sum_{i=1}^Mw_i\frac{i}{b_i-a_i}\int_{a_i}^{b_i}xdx \\
	&= \sum_{i=1}^M\frac{w_i}{b_i-a_i}\Big[\frac{1}{2}x^2\Big|_{a_i}^{b_i} \\
	&= \sum_{i=1}^M\frac{w_i}{b_i-a_i}\frac{b_i^2-a_i^2}{2} \\
	&= \sum_{i=1}^M\frac{w_i}{2}(a_i+b_i)
\end{align*}
\begin{align*}
	\text{var}(x) &= \int_{-\infty}^\infty x^2\sum_{i=1}^Mw_i\frac{1}{b_i-a_i}dx-\mu^2 \\
	&= \sum_{i=1}^M\frac{w_i}{b_i-a_i}\Big[\frac{1}{3}x^3\Big|_{a_i}^{b_i}-\mu^2 \\
	&= \sum_{i=1}^M\frac{w_i}{b_i-a_i}\frac{b_i^3-b_i^3}{3}-\mu^2 
\end{align*}

\subsection*{Problem (b)}
Suppose the $(w_i,a_i,b_i)$ parameters for $M=7$ mixands are specified as follows, in order for components $i=1,\dots,7$:
\begin{equation*}
	(0.1859,-4,-2),\ (0.0961,-2,-1),\ (0.1055,-0.75,0), \\
	(0.2104,0,1),\ (0.0678,3,5.5),\ (0.1950,4,6),\ (0.1393,-0.9,7)
\end{equation*}
Plot the resulting values for $p(x)$ with these mixture parameters over the range $x\in[-6,8]$, using an abscissa step size of $\delta x=0.001$ to evaluate at discrete grid points.

\subparagraph*{}
See figure \ref{AQ2_plot1} below for a plot of the resulting pdf for the given parameters.
\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{AQ2_plot1.png}
	\caption{histogram for mixture model}
	\label{AQ2_plot1}
\end{figure}

\subsection*{Problem (c)}
Use (b)'s results to compute the following via numerical grid-based approximations:
\begin{itemize}
	\item $E[x]$ - how does this compare to the analytical result?
	\item $\text{var}(x)$ - how does this compare to the analytical result?
	\item $H[p(x)]=E[-\log p(x)]$
	\item $KL[p(x)\|q(x)] = E[\log\frac{p(x)}{q(x)}]$
\end{itemize}

\subparagraph*{}
The expected value of $p(x)$ found by numerically integrating $xp(x)$ over $[-6,8]$ is 1.0523. This agrees well with the analytical mean of 1.0518. \\
The variance of $p(x)$ found by numerically integrating $x^2p(x)$ over $[-6,8]$ is 10.2705. This also agrees well with the analytical variance of 10.2695. \\
Because $\log(0)=-\infty$, I dropped any point where $p(x)=0$ from the integration. The numerical integration of $-x\log(p(x))$ resulted in a differetial entropy of 55.3429. \\
I found the Kullbach-Leibler divergence to be -15.527 by numerically integrating $x\log(p(x)/q(x))$, again dropping any values of $p$ or $q$ that would result in an infinite value for the log.

\subsection*{Problem (d)}
Generate random sample sets of size $N=100$, $N=1000$, and $N=50000$ from $p(x)$ and plot the results on histograms with 1000 bins to compare to (b)'s results.

\subparagraph*{}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{AQ2d_plot1.png}
	\caption{histogram for mixture model}
	\label{AQ2d_plot1}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{AQ2d_plot2.png}
	\caption{histogram for mixture model}
	\label{AQ2_plot1}
\end{figure}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.6\linewidth]{AQ2d_plot3.png}
	\caption{histogram for mixture model}
	\label{AQ2d_plot3}
\end{figure}


\subsection*{Problem (e)}
Use each of the sample sets from (d) to produce direct Monte Carlo approximations of the quantities evaluated in (c). How do the results for each sample set size compare to each other and to the results from part (c)?

\end{document}
